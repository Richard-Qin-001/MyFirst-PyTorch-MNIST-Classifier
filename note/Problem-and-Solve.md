# Problem and Solve
## 记遇到的问题以及解决方案
## 1.为何选择PyTorch
PyTorch语法相对简单，可能在业界应用不如Transformer，但作为入门学习，制作一个手写数字识别程序，或许是一个不错的选择，以后有机会我也会试一试Transformer。
## 2.环境安装的问题
我的Laptop使用的是NVIDIA GeForce RTX 5060 Laptop GPU。5060 GPU 使用的是基于 Blackwell 架构，之前的40系列GPU使用的是Ada Lovelace 架构，因此老版本的PyTorch不能支持新版GPU，为了开启GPU加速，一开始尝试了Nightly版本，确实成功支持了，但出现了报错：
```bash
RuntimeError: operator torchvision::nms does not exist
```
查了很多资料，发现是torchvison和torch版本不匹配的问题，但安装的时候二者同时安装的，并没有报错，也满足环境要求，最后参考了https://github.com/Scarfy-sysu/rtx5060-pytorch-cuda129/issues/1 ，卸载，重新安装12.9稳定版，解决。
```bash
pip3 install torch torchvision --index-url https://download.pytorch.org/whl/cu129
```
这种版本问题很难受，以后安装的时候最好让pip自己处理依赖。
## 3.数据预处理流程 (transforms)
transforms.Compose([...]): 这是一个容器，用于将多个转换操作按列表顺序链接起来。一张图片会依次经过列表中的所有操作。

transforms.ToTensor(): 这是最关键的一步。 它做了两件重要的事情：将图像格式从标准的 Python 图像库（PIL）图像转换为 PyTorch 的 torch.Tensor。将图像的像素值从  $0$  到 $255$ 的整数范围，缩放到 $0.0$ 到 $1.0$ 的浮点数范围。这是深度学习模型常用的输入范围。

transforms.Normalize((0.1307,), (0.3081,)): 标准化。 这一步的目的是使数据分布居中，有助于加快梯度下降的收敛速度。对于灰度图 (单通道)，我们只需要一个均值 $(0.1307)$ 和一个标准差 $(0.3081)$ 。

## 4.加载训练集和测试集 (torchvision.datasets.MNIST)
torchvision.datasets.MNIST(...): 这是核心功能，它实例化了一个 MNIST 数据集对象。

root='./data': 指定了数据文件的存储路径。第一次运行时，如果这个文件夹中没有 MNIST 文件，就会触发下载。

train=True 或 train=False: 这是区分训练集和测试集的关键参数。在机器学习中，训练集和测试集必须严格分开，模型只能在训练集上学习，在测试集上评估，否则评估结果将不可信。

在量化交易模型训练的时候，尤其要注意训练集和测试集的区分，部分部分财务报表公布时间可能远远晚于其统计形成的时间，如果把这部分数据放在训练集里面，就相当于模型“偷看”了未来的数据，这样模型训练效果就会下降。

download=True: 允许程序自动下载数据。

transform=transform: 将我们定义的 transform 流程应用到数据集中的每张图片上。
## 5.os库获取文件路径
由于我不想把全部代码都放在一个文件夹里面，我希望源代码，训练数据，测试数据，以及其他文件，都分门别类的放在不同文件夹里面，如果root='./data'，只能在当前文件夹下操作，而使用相对路径也比较复杂。

这时候os库就派上用场了，Python 的内置变量 __file__ 存储了当前执行的 Python 文件的路径，我们使用 os.path 模块的函数来处理这个路径。

__file__: 这是一个由 Python 解释器在运行时设置的特殊变量，它指向正在执行的脚本文件。

os.path.abspath(path): 接收一个路径，返回它的绝对路径形式。无论从哪个目录运行脚本，它都能得到完整的、明确的路径。

os.path.dirname(path): 剥离路径中的文件名，只保留文件所在的目录路径。

os.path.join(path1, path2, ...): 这是在不同操作系统（Windows 使用 \，Linux/macOS 使用 /）上安全地拼接路径的方法。

os库还能用来打开和写入文件，配合json库使用可以极大简化数据处理的流程，比起C++需要使用第三方库处理json来看，Python强大的标准库和丰富的生态确实极大简化了编程过程。

## 6.数据加载器 (DataLoader)
DataLoader 的作用就像一个高效的传送带，它负责将整个数据集：

1.按我们定义的 BATCH_SIZE 分批次地取出。

2.在训练时打乱（shuffle）顺序，防止模型记住数据顺序。

3.可以使用多进程并行加载，避免 GPU 在等待数据时处于空闲状态。

torch.utils.data.DataLoader: 这是一个迭代器，可以用 for 循环遍历它来获取数据批次。
batch_size=BATCH_SIZE: 我们之前定义的 $64$。
shuffle=True: 仅用于训练集。 在每个训练周期 (Epoch) 开始前，打乱数据的顺序。
shuffle=False: 仅用于测试集。 保持测试集的数据顺序不变，以确保评估结果的一致性。
num_workers=4: 允许系统使用 $4$ 个额外的 CPU 核心来提前加载数据。

## 7.将模型的所有参数从 CPU 传输到 GPU 显存中
```Python
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model.to(device)
```

## 8.Python 的标准多进程惯用法
将所有不是定义（如函数定义、类定义）的代码，都包裹在 if __name__ == '__main__': 条件块中。
这个条件的作用是：只有当脚本作为主程序直接执行时（而不是被其他进程导入时），才执行包裹在其中的代码。

### 在 Windows 系统上，Python 启动子进程的方式叫做 “Spawn”（衍生）。
主进程启动： 当运行 python mnist_classifier.py 时，主进程开始执行脚本。
遇到 DataLoader： 当主进程执行到 DataLoader 并发现 num_workers 大于 $0$ 时，它需要启动多个子进程（Worker 进程）来并行加载数据。
子进程“克隆”： 为了让子进程知道要做什么，Windows 的 Spawn 机制会让子进程重新导入并执行一遍整个 Python 脚本。无限递归循环： 如果没有使用 ``` if __name__ == '__main__':```，那么当子进程重新执行脚本时，它会从头到尾执行所有代码，包括：导入语句数据加载语句创建 DataLoader 的语句创建 DataLoader 语句 又会试图启动新的子进程...
崩溃： 这样就形成了一个无限的、递归启动子进程的循环，最终导致系统资源耗尽并抛出``` RuntimeError: An attempt has been made to start a new process... ```的错误。

### ``` if __name__ == '__main__':``` 如何解决问题？
Python 解释器会为它执行的每一个模块或脚本设置一个特殊的内置变量```  __name__```：

作为主脚本运行时： 当您直接运行 python your_script.py 时，该脚本的 ```  __name__``` 变量的值会被设置为字符串 ``` '__main__' ```。

作为模块被导入时： 当其他模块（例如 DataLoader 启动的子进程）导入您的脚本时，该脚本的 ``` __name__``` 变量的值会被设置为脚本的文件名（例如 'mnist_classifier'）。

通过将执行性的代码（例如：设备设置、数据加载、DataLoader 创建、训练循环等）放入``` if __name__ == '__main__': ```块中，我们实现了：

主进程：```  __name__``` 等于``` '__main__'```，条件成立，执行代码，启动 DataLoader。

子进程： 子进程导入脚本，```  __name__``` 等于 ``` 'mnist_classifier' ```，条件不成立，跳过 DataLoader 创建等执行代码，子进程只保留了函数和类定义，从而避免了无限递归启动，程序得以正常运行。

## 9.神经网络模型 (CNN)
实现卷积神经网络 (Convolutional Neural Network, CNN)，定义 CNN 模型类。
我认为类最重要的内容之一就是继承，专门写了一个class-in-python.md在note文件夹内。
__init__ (初始化)： 定义网络结构所需的各种“层”或“模块”。
forward (前向传播)： 定义数据 $x$ 如何流过这些层。
nn.Conv2d： 提取特征。它扫描图像并输出特征图 (Feature Map)。
F.relu： 激活函数。引入非线性，让网络能学习更复杂的模式。
F.max_pool2d： 池化层。降低特征图的空间维度（长和宽），减少计算量，并提供一定的平移不变性。
x.view(-1, 320)： 将二维特征图（例如 $20$ 个通道，每个通道是 $4 \times 4$）展平成一个长向量 ($20 \times 4 \times 4 = 320$)，以便连接到全连接层。
nn.Linear： 全连接层。负责将展平后的特征映射到最终的 $10$ 个类别。

卷积神经网络还是比较复杂的，让Gemini写了点概念，贴在下面：

### 1. CNN 的定位：

CNN（卷积神经网络）是一种专门设计用于处理网格结构数据的神经网络，例如图像（二维网格）或时间序列（一维网格）。

它是目前计算机视觉领域（如图像识别、目标检测）最主流的模型。

### 2. 核心结构：

一个 CNN 通常由以下三类关键层交替堆叠而成：

卷积层 (Convolutional Layer)：用于提取特征。

池化层 (Pooling Layer)：用于降采样和保持不变性。

全连接层 (Fully Connected Layer)：用于最终的分类或决策。

### 卷积层（Convolutional Layer）卷积层是 CNN 的“大脑”，它负责自动学习和提取输入数据中的空间特征。
1. 卷积核（Kernel 或 Filter）概念：卷积核是一个小型矩阵（例如 $3 \times 3$ 或 $5 \times 5$），它包含了一组需要通过训练学习的权重。
操作：卷积核在输入图像上滑动（或称“卷积”）。
在每一步，它将自身的权重与覆盖区域的像素值进行点乘求和，然后加上一个偏置项，生成输出图上的一个像素值。作用：每一个卷积核专门负责提取输入中的一种特定特征（比如：垂直边缘、水平边缘、某个特定的颜色或纹理）。
2. 特征图（Feature Map）卷积核滑完整个输入图像后，所得到的二维输出结果，我们就称之为特征图。
如果一层卷积层使用了 $N$ 个不同的卷积核，那么它就会产生 $N$ 个不同的特征图，共同构成了这一层的输出。
3. 核心优势：局部感知与参数共享局部感知（Local Receptive Fields）：一个神经元（输出特征图上的一个点）只关注输入图像的一个局部小区域。这模仿了生物的视觉系统，大大减少了连接数和参数数量。
参数共享（Parameter Sharing）：一个卷积核在图像的所有位置上都使用同一套权重。这意味着学习到的边缘检测器在图像的左上角、右下角都能起作用，从而大幅减少了需要训练的参数，并让网络具备平移不变性（即物体移动了位置也能被识别）。

看到这里我补充一点，卷积核有很多个是因为不同卷积核要识别不同区域的图像特征，这与每个卷积核都要滑过整个图像并不冲突。图像中的物体或特征可以在任何位置出现（例如，一只猫可以在图片的左上角或右下角）。因为我们让同一个卷积核（即同一套权重）滑动到图像的每个位置去计算特征，所以这个核学到的“边缘检测”能力，无论边缘出现在图像的哪个位置，它都能成功检测出来。这使得网络具备了对物体位置的平移不变性（Translation Invariance），极大地提高了模型的鲁棒性。这一点我觉得需要理解。

既然上面说到每个卷积核负责识别不同特征，那么卷积核越小越好吗？显然不是，1*1的卷积核显然没用，因此卷积核不一定越小越好，但小型卷积核（特别是 $3 \times 3$）在现代深度学习中非常流行和高效。用多个小型卷积核堆叠起来，可以达到与一个大型卷积核相同的感受野（Receptive Field），但参数量更少。使用多个 $3 \times 3$ 卷积核代替一个大型卷积核，可以显著减少参数量。每增加一层卷积层，都会伴随一次激活函数（如 ReLU）的非线性处理。用多层 $3 \times 3$ 代替一层大核，网络可以引入更多的非线性，从而学习更复杂、更抽象的特征。

### 池化层（Pooling Layer）
池化层通常紧跟在卷积层和激活函数之后。
它的主要目标是：
减少数据的维度（降采样），从而减少网络参数和计算量。
增强特征的鲁棒性，使其对位置的微小变化不那么敏感。
1. 工作原理：降采样池化层通过在一个小区域内进行聚合操作来实现降采样。最常用的池化方法是最大池化（Max Pooling）。操作：池化操作会定义一个小的滑动窗口（例如 $2 \times 2$），然后让这个窗口在输入的特征图上滑动。最大池化：在窗口覆盖的区域内，只取出最大的那个数值作为输出。降维效果：如果使用 $2 \times 2$ 的窗口和步长 $2$ 进行最大池化，那么输出特征图的宽度和高度都会是输入特征图的一半，体积将减少到原来的四分之一。
2. 核心作用：鲁棒性平移不变性（Translation Invariance）：由于最大池化只关心区域内的最大激活值，如果原始特征（例如一个角点）在输入图像中发生了微小的偏移（比如在 $2 \times 2$ 窗口内移动了一个像素），池化后的输出最大值很可能保持不变。这使得网络对图像中物体的位置变化具有更强的容忍度（鲁棒性）。保留重要信息：在特征图中，高数值代表该位置存在某种重要特征。最大池化保留了区域内最强的激活信号，相当于只保留了最重要的特征信息，而丢弃了不重要的细节。

### 全连接层（Fully Connected Layer, FC）
经过多层卷积和池化操作后，网络已经成功地从原始像素中提取出了一系列高级的、鲁棒的特征。
现在需要利用这些特征来做出最终的决策（例如，分类）。
1. 展平（Flatten）目的：卷积和池化层的输出是三维的（宽度 $\times$ 高度 $\times$ 深度）。全连接层需要一个一维向量作为输入。操作：在进入第一个全连接层之前，需要将最后一个池化层输出的三维数据展开成一个单一的长向量。这个向量包含了所有提取到的高级特征信息。
2. 全连接层的操作概念：全连接层就是我们最初讨论的标准神经网络层，其中当前层的所有神经元都与前一层的所有神经元完全连接。作用：它将卷积和池化提取的空间特征（如“猫的眼睛”特征）映射到最终的类别标签空间。FC 层学会了如何根据特征向量中各种特征的组合和强度来识别物体。
3. 输出层最后一个全连接层通常是输出层。激活函数：对于多分类问题，输出层会使用 Softmax 激活函数，将全连接层的输出数值转化为每个类别的概率。例如，输出 $[0.05, 0.9, 0.05]$，意味着网络判断输入图像是“猫”的概率为 $90\%$。

CNN 模型的结构分解：

|层类型|作用|对应的 PyTorch 模块|
| ---- | ---- | ---- |
卷积层 (Conv)|提取图像的局部特征。|nn.Conv2d|
全连接层 (FC)|将提取到的特征映射到最终的分类结果。|nn.Linear|
Dropout 层|随机关闭一些神经元，防止模型在训练集上学习得太死板（过拟合）。|nn.Dropout2d|

在这一段代码中基本都写了注释。

### 注意 320 如何计算

320 这个数字，是图像经过所有卷积层和池化层之后，最终剩下的特征图的体积。
320 的计算过程（公式推导）
我们的 MNIST 图像是 $ 1 \times 28 \times 28 $（通道 $ \times $ 高 $ \times $ 宽）。我们必须一步步计算每次操作后图像尺寸的变化。
1. 卷积层 1 (self.conv1)

| 操作 | 图像尺寸 (输入) | 参数 | 图像尺寸 (输出) | 解释 |
|---|---|---|---|---|
| 输入 | 1 \times 28 \times 28 |  |  | 原始 MNIST 图像 |
| Conv1 | 1 \times 28 \times 28 | k=5, p=0, s=1 | 10 \times 24 \times 24 | 公式： $ W_{out} = \frac{W_{in} - k + 2p}{s} + 1 = \frac{28 - 5 + 0}{1} + 1 = 24 $ |
| Max Pool 1 | 10 \times 24 \times 24 | k=2, s=2 | 10 \times 12 \times 12 | 公式：$ W_{out} = \frac{24}{2} = 12 $ |

 * 注意： 我们使用了默认的填充 p=0 和步长 s=1。池化层 F.max_pool2d(x, 2) 的窗口大小 k=2，步长 s=2。

2. 卷积层 2 (self.conv2)

| 操作 | 图像尺寸 (输入) | 参数 | 图像尺寸 (输出) | 解释 |
|---|---|---|---|---|
| 输入 | 10 \times 12 \times 12 |  |  | 上一步的输出 |
| Conv2 | 10 \times 12 \times 12 | k=5, p=0, s=1 | 20 \times 8 \times 8 | 公式： $ W_{out} = \frac{12 - 5 + 0}{1} + 1 = 8 $ |
| Max Pool 2 | 20 \times 8 \times 8 | k=2, s=2 | 20 \times 4 \times 4 | 公式：$ W_{out} = \frac{8}{2} = 4 $ |

3. 展平 (Flatten)
经过所有卷积和池化操作后，我们得到了 20 个通道，每个通道的特征图大小是 $ 4 \times 4 $ 。
在连接到全连接层 (nn.Linear) 之前，我们需要将这个三维张量 展平 (Flatten) 成一个一维向量：
总结
因此，最终的 320 就是这样计算出来的：它是第二个池化层之后的特征图体积，也就是 $ \text{通道数} \times \text{高度} \times \text{宽度} = 20 \times 4 \times 4 $ 。
在设计自己的 CNN 模型时，如果改变了卷积核大小 (k)、步长 (s) 或池化窗口大小，这个展平后的数字也会随之改变，必须重新计算它，否则模型就会报错。

激活函数 (F.relu)： 是深度学习的核心。它的数学表达是 $f(z) = \max(0, z)$。它引入了非线性，使得网络能够学习和逼近复杂的、非线性的决策边界，这是没有激活函数无法做到的。
池化层 (F.max_pool2d)： 它的主要作用是下采样。在 $2 \times 2$ 的窗口上取最大值，这使得模型对输入图像的微小平移、旋转具有一定的不变性。
展平 (x.view(...))： 在 PyTorch 中，x.view(x.size(0), -1) 是将张量在保持第一个维度（批量大小）不变的情况下，把后续所有维度（通道、高、宽）展平成一维，以便喂给全连接层。

## 10.模型实例化与训练准备
model.to(device)： 它将模型对象 SimpleCNN 及其内部所有可学习参数（权重和偏置）一次性复制到 GPU 显存中。
损失函数 (nn.CrossEntropyLoss)：作用： 衡量模型的预测值与真实标签之间的差距。差距越大，损失值越高。
为什么用它？ 它是图像分类任务的标准选择。它接收模型的原始输出（称为 Logits）和正确的类别标签，计算出一个衡量错误的标量值。
优化器 (torch.optim.Adam)：作用： 根据损失函数计算出的误差（梯度），更新模型的参数（权重和偏置），使损失函数的值逐渐减小。lr=0.001 (学习率)： 这是优化器更新参数的步长。如果太高，模型会不稳定；如果太低，训练会非常慢。$0.001$ 是一个很好的起始值。

## 11.模型训练循环 (Train Loop)

定义两个函数：一个用于训练 (学习)，一个用于测试 (评估)。

data.to(device), target.to(device)： 这是将数据从 CPU 内存传输到 GPU 显存的关键代码。

optimizer.zero_grad()： 极其重要！ 梯度是累加的。如果您不清零，当前批次的梯度会和上一个批次的梯度混在一起，导致参数更新错误。

loss.backward()： 根据计算图（Computational Graph），从损失值反向追溯到模型中的每个参数，计算出每个参数应该如何调整才能降低损失（即计算梯度）。

optimizer.step()： 优化器利用计算出的梯度，结合学习率 (lr=0.001) 和优化算法（Adam），对模型参数进行微小的调整。

model.eval()： 非常重要！ 将模型设置为评估模式。这会冻结 nn.Dropout 和 nn.BatchNorm 等层的行为，确保它们在测试时不会引入随机性或使用批量统计量，从而保证评估结果的确定性。
with torch.no_grad():： 必须使用！ 这是告诉 PyTorch 在这个代码块内，不要为任何计算构建计算图，也不要存储用于反向传播的中间值。这可以节省大量的 GPU 显存和计算时间。
计算预测值：
output.data.max(1, keepdim=True)[1]：模型输出 output 是 $10$ 个类别的 Logits。max(1) 沿着第二个维度（索引为 $1$，即类别维度）找到概率最大的那个索引，这个索引就是我们模型的预测结果 pred。

## 12.主训练流程 (Main Execution)
for epoch in range(1, NUM_EPOCHS + 1)： 外层循环，控制模型“看”整个数据集的次数（我们设置了 $10$ 次）。

train(...) 和 test(...)： 在每个周期内依次调用训练和测试函数。

模型保存 (torch.save(...))：state_dict()：这是 PyTorch 保存模型时最常用的方法，它只保存模型的可学习参数（权重和偏置），而不是整个类定义，这样文件更小、兼容性更好。

os.makedirs(..., exist_ok=True)：确保保存模型的 models 文件夹存在，如果不存在则创建。我们只在当前的测试准确率 (current_accuracy) 超过历史最佳 (best_accuracy) 时才保存模型，确保我们保留的是效果最好的模型。

## 13.实现断点续训逻辑

为了实现续训，我们不仅需要加载模型的权重，还需要加载优化器 (optimizer) 的状态。

为了支持断点续训，模型保存时不能只保存 model.state_dict()，而应该保存一个包含所有信息的检查点 (Checkpoint) 字典。

第一次运行： 运行 mnist_classifier.py，它会从 epoch 1 开始训练，直到 epoch 10 结束，并保存最佳检查点。
中断训练（例如只跑到 epoch 5）： 如果在第 5 个周期停止了程序。
恢复训练： 再次运行 mnist_classifier.py。脚本会检测到 mnist_cnn_best.pth 文件。它会从检查点中读取 epoch 为 $5$。训练将从 range(6, 10 + 1)，即第 $6$ 个周期继续，直到第 $10$ 个周期结束。

## 14.JSON文件的读取
os库提供了打开JSON文件的方法：
```Python
with open(json_path, 'r', encoding='utf-8') as f:
    test_list = json.load(f)
```
open()函数的第一个参数是JSON文件的路径，支持相对路径和绝对路径，这里我使用的绝对路径；第二个参数是打开的类型，这里我们只需要读就行，于是'r'只读,'w'是只写，'rw'是读写，顺便一提，Python 中''和""作用一样，不区分字符和字符串；as f是把打开的文件赋值给了变量f，接下来只需要操作f就行了。:里面的内容是对f进行的操作，这里用Python标准库json提供的load方法，可以把文件内容读取出来，存在列表中。

## 15.待解决的问题
模型在测试数据上准确率在30次训练之后可以达到99%，但是我自己写了10个数字，测试出来准确率只有30%。
查阅资料发现MNIST提供的数据是黑底白字，我的图片是白底黑字，于是加了一个强制黑白反转的功能。
之后准确率确有提升，到了70%，但是与我们99%的目标相差太远了。
到目前为止，没有想到是哪里有问题，让我多想一想。

## 16.结语
实际上学习难度还是有的，但是熟悉了Python基本语法也不会很困难，要想代码写得快，还是得熟练得用自己熟悉的结构类型，变量和函数命名，以及熟悉函数的参数。
另外，Gemini实在太强大了，对这种小项目不需要开推理就能很快的找出解决问题。

### 竹枝词

刘禹锡

杨柳青青江水平，闻郎江上唱歌声。
东边日出西边雨，道是无晴还有晴。